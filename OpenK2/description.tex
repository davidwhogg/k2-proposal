% This file is part of the OpenK2 project.
% Copyright 2015 the authors.

% ## style notes:
% - Use \textbf{} for emphasis of key deliverables or proposed items.

% ## issues:
% - DFM:  WE NEED TO SAY SOMETHING SENSIBLE ABOUT EXPECTED YIELDS, here and in summary
% -

\documentclass[12pt,preprint]{aastex}
\setlength{\headheight}{2ex}
\setlength{\headsep}{3ex}
\input{hogg_nasa}
\pagestyle{myheadings}
\markright{\textsf{\shortauthor~/~\fulltitle}}
\usepackage{url}
\usepackage{hyperref}

\newcommand{\github}{\project{GitHub}}

\begin{document}

\emph{The \kepler\ Spacecraft changed the world.}

Or the world of exoplanets, at least.
It found thousands of exoplanet candidates and more than a thousand
confirmed exoplanets.
With a four-year mission and part-in-$10^5$ precision time-domain
measurements of the brightnesses of $10^5$ stars, it is sensitive to
transits of true Earth analog planets (planets on year-ish orbits with
Earth-ish radii around Sun-like stars).
It hasn't quite found a perfect Earth analog, but it has found planets
in a wide range of orbits and with a wide range of properties, and
also done a huge amount to constrain the abundance of Earth-like and
(potentially) habitable planets.

Now that the \kepler\ Main Mission is over (ended by the failure of a
second reaction wheel), the Spacecraft is operating in a new mode,
\kt.
In this mode, the Spacecraft is scheduled to observe a set of at least 12
fields around the ecliptic plane, each for about 80 days at a time.
\kt\ is observing for less time on any particular star than in the
Main Mission, but it is covering a wider range of stars in a wider
range of environments.
For example, the \kt\ Campaigns include cluster stars as well as field
stars, which opens up significant discovery space (and significantly
complexifies data-analysis pipelines).
For another example, it is focusing on lower-mass stars, which are now
known to have more abundant planets than Sun-like stars and which
serve as hosts to planets on shorter-period orbits.
In the course of its 12 Campaigns---its observations of its 12
fields---\kt\ will produce data containing an abundance of exoplanets as
impressive and important as that from the original \kepler\ Main
Mission.

There is one missing piece, however:
From each Campaign, the \kt\ project is delivering image patches (one
patch per star or star cluster every 30~min for 80 to 90~days), but it
is not delivering lists of detected exoplanets.
Unlike the \kepler\ Main Mission, the \kt\ deliverables are only raw
data.
\textbf{Here we propose to deliver the exoplanet catalog for \kt,
along with the information and tools required to use it responsibly}
for statistical studies of exoplanets.

There are also interesting and valuable technical challenges brought
by the \kt\ data.
One is that the Spacecraft pointing is much less stable for \kt\ than
it was for the \kepler\ Main Mission.
This means that far more attention must be paid to instrument-induced
effects, especially when we care (as we do) about very small planets.
This accounting for instrumental noise (or calibration, if you will)
is our specialty, and the thing we do best in the community.

Another interesting technical challenge relates to the brief duration
of the \kt\ Campaigns.
Coming in at a few months, they are intermediate between \kepler\ Main
Mission (four years) and the upcoming NASA \tess\ Mission (one month for most of the sky).
This means that even short-period exoplanets do not provide many
transits; the importance of obtaining significance at the
individual-transit level is high.
Everything we learn along these lines in working on \kt\ is very
relevant to the near-future of NASA exoplanet science with \tess.

While the \kepler\ Main Mission data provided critical information
about the population of exoplanets around field G-dwarf (and similar) stars
in (and near) the Milky Way disk, the \kt\ project will span much more
territory in host-star space.
After \kt, we will know about exoplanet populations around other kinds
of stars (particularly cooler stars), around stars in stellar clusters
of a range of ages, and around Milky Way halo stars.
It will be critical to understand these populations, and their
dependencies on stellar type and environment.
\textbf{Here we propose to perform this populations inference, taking
  into account Catalog incompleteness and accounting for observational
  uncertainties.}
We usually describe this population inference as a determination of the
rate at which stars host planets, as a function of planet properties
(period and radius, for example), and conditioned on the stellar type
(temperature, surface gravity, metallicity, and environment).

Population inferences to date with \kepler\ Main Mission data
\citep{Youdin:2011, Howard:2012, Dong:2013, Petigura:2013,
Foreman-Mackey:2014, Dressing:2015} have
mostly focused on G-type stars (and similar) and have varied in levels of
statistical sophistication.
We are currently the only group that has fully accounted for
observational uncertainties (in particular in planet radii) by means
of a method that is justified probabilistically and is based
completely on forward modeling noisy data from noiseless samples from
a true (inferred) distribution \citep{Foreman-Mackey:2014}.
Planet radii are always poorly known (always have significant
uncertainty), in part because stellar models do not deliver precise
\emph{stellar radii}, and transit measurements only really constrain
\emph{relative} sizes of planets and their host stars.
And (because of the shorter per-star observation duration),
\kt\ exoplanets will have larger uncertainties than Main-Mission
planets in all their properties.
At the present day, we are the best investigators to undertake this
populations inference.
(Of course all our code is available open-source on public
\github\ repositories, so we are doing our best to put
ourselves out of business!)

In the long run, NASA's goals include characterization, including by
direct imaging and spectroscopy, rocky, habitable extra-solar planets.
This ambitious goal is well served by the \kepler\ and \kt\ Missions.
Everything we propose here is aligned with this long-term goal:
We expect \kt\ to deliver dozens to hundreds of habitable-zone
planets, and our populations work to date has been focused on
understanding the smallest planets, which we now know to be rocky
\citep{Rogers:2015}.
In addition, and not irrelevant, the openness with which the
\kepler\ Team has shared its data and results, and the openness built
into the design of the \kt\ and \tess\ Missions will serve well NASA's
long-term goals, especially when combined with open-source development
of the best methods for data analysis and inference by the expert
community.
It is our privilege and pleasure to play a role in this ``Comedy of
the Commons'' in which open data and open-source code have led to an
acceleration of discovery and knowledge generation aligned with
important US priorities.

One final note about our proposal---\thecatalog.
This is an exoplanet catalog built with the primary mission of understanding exoplanet \emph{populations}.
Useful for follow up...
but needs incompleteness and uncertainties...
Must test our populations-appropriateness by doing them...

\section{The first Open \ketu\ Catalog}

We have made the first steps towards building an open \ketu\ catalog by
developing a method of transit search that is robust to the large systematic
effects in the \ketu\ light curves, publishing a list of planet candidates
from the first Campaign of the \ketu\ Mission, and releasing an open source
implementation of the method\footnote{\url{https://github.com/dfm/ketu}}
\citep{Foreman-Mackey:2015}.
Of the 36 published planet candidates, 2 were previously known
\citep{Crossfield:2015} and 16 others have since been confirmed as bona fide
planets \citep{Armstrong:2015, Montet:2015}.
This transit search procedure was designed to be sensitive to the transits of
small planets even in the face of the degraded pointing of the \kepler\
spacecraft by using a data-driven, causal model for the systematic photometric
variability of the light curves.

In order to discover transiting planets, exquisite photometric precision is
crucial.
Good photometry relies on either a near-perfect flat-field
and pointing model or else data-analysis techniques that are
insensitive to these instrument properties.
The flat-field for \kepler\ was measured on the ground before the launch of
the spacecraft, but is not nearly as accurate as required to make
pointing-insensitive photometric measurements at the relevant level of
precision.
In principle direct inference of the flat-field might be possible;
however, because point sources are observed with relatively limited
spacecraft motion, and only a few percent of the data are actually stored and
downloaded to Earth, there isn't enough information in the data to derive or
infer a complete or accurate flat-field map.
Therefore, work on \KT\ is sensibly focused on building data-analysis
techniques that are pointing-insensitive.

Previous projects have developed methods to work with \KT\ data.
Both \citet{Vanderburg:2014} and \citet{Armstrong:2014}
extract aperture photometry from the pixel data
and decorrelate with image centroid position, producing light curves for each
star that are ``corrected'' for the spacecraft motion.
These data have produced the first confirmed planet found with
\KT\ \citep{Vanderburg:2015}.
Both \citet{Aigrain:2015} and \citet{Crossfield:2015} use a Gaussian Process
model for the measured flux, with pointing measurements as the inputs, and
then ``de-trend'' using the mean prediction from that model.
Other data-driven approaches have been developed and applied to the data from
space missions \citep[for example,][]{Ofir:2010, Stumpe:2012, Smith:2012,
Petigura:2013, Wang:2015} and ground-based surveys \citep[for
example,][]{Kovacs:2005, Tamuz:2005, Berta:2012} but they have yet to be
generalized to \KT.

In all of these light-curve processing methodologies, the authors follow a
traditional procedure of ``correcting'' or ``de-trending'' the light curve to
remove systematic and stellar variability as a step that happens \emph{before}
the search for transiting planets.
Fit-and-subtract is dangerous:
Small signals, such as planet transits, can be
partially absorbed into the best-fit stellar variability or systematics
models, making each individual transit event appear shallower.
In other words, the traditional methods are prone to over-fitting.
Because over-fitting will in general reduce the amplitude of true exoplanet
signals, small planets that ought to appear just above any specific
signal-to-noise or depth threshold could be missed because of the de-trending.
This becomes especially important as the amplitude of the noise increases.

The alternative to this approach is to \emph{simultaneously fit} both the
systematics and the transit signals.
Simultaneous fitting can push the detection limits to lower signal-to-noise
while robustly accounting for uncertainties about the systematic trends.
In particular, it permits us to \emph{marginalize} over choices in the noise
model and propagate any uncertainties about the systematic effects
to our confidence in the detection.
This marginalization ensures that any conclusions we come to about the
exoplanet properties are conservative, given the freedom of the systematics
model.

\paragraph{A data-driven model of photometric systematics}

To model the large systematics in the \ketu\ light curves,
\citet{Foreman-Mackey:2015} developed a data-driven model using the shared
systematic trends between light curves observed simultaneously with the same
instrument.

HOGG: how many details do we want here?


\section{\thecatalog}

In principle, the methods that we have previously developed
\citep{Foreman-Mackey:2015} are applicable to each Campaign and it can be used
to produce a relatively homogeneous and consistent catalog of planets and
planet candidates across the full baseline of the \kt\ Mission.
A systematic, automated catalog of planet candidates (with characterized
completeness and false positive rate) is essential for population inference
studies: the main strength of the \kt\ dataset.
The pipeline in its current version can be directly applied to most targets in
the upcoming Campaigns (except, perhaps, Campaign~9, which is directed towards
a crowded field in the Galactic bulge) but, as described below, we have
various suggestions for making the transit search and vetting procedures more
sensitive and robust.

We propose to continue developing this transit search pipeline and apply it
immediately to upcoming \kt\ data releases.
Processing a Campaign of \kt\ photometry and empirically measuring the search
completeness currently requires about a week of computation on NYU's High
Performance Computing resources.
This should enable a release of planet candidates and the products necessary
for population inference within about two weeks of the data release.
We will immediately push our discoveries to \github\ (as part of the Open \kt\
Initiative\footnote{\url{https://github.com/OpenK2}}) and to the Exoplanet
Follow-up Observing Program for \kt\
(\project{ExoFOP-K2}\footnote{\url{https://cfop.ipac.caltech.edu/k2/}})
repository.

As we continue to improve the search procedures, we will re-analyze the
previous Campaigns and publish updated candidate lists to the same data hosts.
Both \github\ and \project{ExoFOP-K2} allow fine-grain versioning and tracking
of the history of changes.


\section{Development and enhancements}

Hello World!  We need a better title for this section

DFM:  Laundry list here (to start)

better basis vectors

more insanely: GP of basis vectors?  Or GPLVM noise model?

prior over basis-vector amplitudes

elimination of hand vetting (progress towards that?)

better photometry of the sources; focal-plane modeling perhaps?

other shit?

\section{Population inferences}

DFM:  Hello World!

DFM:  Populations conditional on stellar type and environment!

DWH:  We must make the point that we will not believe \thecatalog\ is filled
with correctness if we don't do science with it; populations is the hardest
part of this.

\section{Culture change in exoplanet science}

The \kepler\ Mission has had a huge impact on the way science is done,
in exoplanet science and across astrophysics.
When the Mission switched to a fully open data release policy, there
was an immediate and noticeable jump in the number of groups working on
the data, publications related to \kepler, and citations of \kepler
publications, results, and data.
There has been no better evidence for the pragmatic value of open
science principles than this.

Our collaboration (the PI and Co-I) has had openness at its core from
the very beginning.
Our highest-impact joint publication so far is an open-source tool for
Markov Chain Monte Carlo sampling in probabilistic inference (\citealt{emcee}).
All of the work we do, all code, all papers, all catalogs, all results
at all intermediate stages (including the writing of this
proposal\footnote{available at
  \url{https://github.com/davidwhogg/k2-proposal}}) is all visible on
the Web at all times.
We have found this approach to be very valuable to us; it leads to
exposure in the community, brings us real-time feedback on our
activities, creates ideas for collaborations with other scientists,
and provides tools for other investigations.

This openness also makes us consistent with current ideas and research
on reproducibility in science:
Everything we have published can be reproduced with a \package{git~clone}
operation and a few command-line executions.
There is a growing sense that this is a necessary part of maintaining
the provenance, reliability, and specificity of the scientific literature,
especially now that data analyses are becoming non-trivial.

We see \thecatalog\ as building on and contributing to the openness
that has worked so well for us and for the exoplanet community.
An open catalog of exoplanet candidates, released promptly after
the Campaigns are released, permits rapid follow-up by groups with
telescope access and theoretical tools, without the requirement that
each of these groups individually perform its own duplicative searches.
Furthermore, some of the technical challenges we have solved for
exoplanet search are non-trivial; it is valuable for the whole community
to benefit from them.
As we have emphasized, this openness is not selfless; we expect the
Catalogs we release to generate abundant citations for our work.

\section{Management plan and data release}

This project is extremely streamlined:
The postdoctoral scholar will do most of the heavy lifting.
He or she will run the catalog generation,
implement the pipeline improvements and enhancements,
and perform the hierarchical population inferences.
The postdoc will also be responsible for writing up the key papers
on searches, Catalogs, and population inferences.

Co-I Foreman-Mackey will supervise on all methodological and exoplanetary
matters.
He will help the postdoc with learning, conceptualizing, implementing,
and testing code enhancements and population inferences.
He will help with writing the scientific and technical papers.
He is an unfunded Co-I because he will be supported by a NASA Sagan
Fellowship for most of the project duration.
This project is perfectly aligned with his Sagan proposal and projects;
this does not represent any ``creep of scope'' for him.

PI Hogg will be the supervisor for the postdoc.
He will be responsible for ensuring that catalogs get released and
papers get written.
He will also be responsible for career development and mentoring
of the postdoc.
He will negotiate agreements (if any are necessary) with the NASA
Archives and companies that will preserve the data products and code.

As for timeline, the key idea is that catalogs will be produced and
released on a short timescale (days) after each \kt\ Campaign data
release.
These catalogs will all have associated completeness simulations
and summary completeness information.
Enhancements to the pipelines be developed in parallel with Catalog
generation.
This means that new Catalogs will be made with different pipeline
versions.
We will implement clear versioning and change logs so this is
comprehensible to our users.
Once per year, we will re-run all past Campaigns with the most recent
pipeline versions and deliver new Catalogs (again with clear
provenance).
The \kt\ Mission will end prior to the end of this granting period;
this gives us time to do a close-out, running declared-final pipelines
on all data.

Also in parallel, we will develop and run our populations inference
machinery.
The most important populations results will require all (or many) of
the Campaigns, so most of our final results will be completed and
published in the final year of the project.

We will work with NYU ITS and also \github\ to preserve
the code and its version history in open repositories on the Web.
We will work with NYU ITS and also the NASA-funded exoplanet
science archives
to publish and preserve \thecatalog\ and all its versions, along with the
completeness analyses (and, as noted above (DWH?), all the
completeness simulation inputs and outputs).

\clearpage
\newcommand{\arxiv}[1]{{\href{http://arxiv.org/abs/#1}{arXiv:{#1}}}}
\begin{thebibliography}{}\raggedright%
\setlength{\itemsep}{0ex}%
\setlength{\parskip}{0ex}%
\bibitem[Aigrain \etal(2015)]{Aigrain:2015}
Aigrain, S., Hodgkin, S.~T., Irwin, M.~J., Lewis, J.~R., \& Roberts, S.~J.\
2015, \mnras, 447, 2880

\bibitem[Armstrong \etal(2014)]{Armstrong:2014}
Armstrong, D.~J., Osborn, H.~P., Brown, D.~J.~A., \etal\ 2014,
\arxiv{1411.6830}

\bibitem[Armstrong \etal(2015)]{Armstrong:2015}
Armstrong, D.~J., Veras, D., Barros, S.~C.~C., \etal\ 2015, \arxiv{1503.00692}

\bibitem[Berta \etal(2012)]{Berta:2012}
Berta, Z.~K., Irwin, J., Charbonneau, D., Burke, C.~J., \& Falco, E.~E.\ 2012,
\aj, 144, 145

\bibitem[Crossfield \etal(2015)]{Crossfield:2015}
Crossfield, I.~J.~M., Petigura, E., Schlieder, J.~E., \etal\ 2015, \apj, 804,
10

\bibitem[Dressing \& Charbonneau(2015)]{Dressing:2015}
Dressing, C.~D., \& Charbonneau, D.\ 2015, \arxiv{1501.01623}

\bibitem[Dong \& Zhu(2013)]{Dong:2013}
Dong, S., \& Zhu, Z.\ 2013, \apj, 778, 53

\bibitem[Foreman-Mackey \etal(2013)]{emcee} Foreman-Mackey,
D., Hogg, D.~W., Lang, D., \& Goodman, J.\ 2013, \pasp, 125, 306

\bibitem[Foreman-Mackey \etal(2014)]{Foreman-Mackey:2014}
Foreman-Mackey, D., Hogg, D.~W., \& Morton, T.~D.\ 2014, \apj, 795, 64

\bibitem[Foreman-Mackey \etal(2015)]{Foreman-Mackey:2015}
Foreman-Mackey, D., Montet, B.~T., Hogg, D.~W., \etal\ 2015, \arxiv{1502.04715}

\bibitem[Howard \etal(2012)]{Howard:2012}
Howard, A.~W., Marcy, G.~W., Bryson, S.~T., \etal\ 2012, \apjs, 201, 15

\bibitem[Kov{\'a}cs \etal(2005)]{Kovacs:2005}
Kov{\'a}cs, G., Bakos, G., \& Noyes, R.~W.\ 2005, \mnras, 356, 557

\bibitem[Montet \etal(2015)]{Montet:2015}
Montet, B.~T., Morton, T.~D., Foreman-Mackey, D., \etal\ 2015,
\arxiv{1503.07866}

\bibitem[Ofir \etal(2010)]{Ofir:2010}
Ofir, A., Alonso, R., Bonomo, A.~S., \etal\ 2010, \mnras, 404, L99

\bibitem[Petigura \etal(2013)]{Petigura:2013}
Petigura, E.~A., Howard, A.~W., \& Marcy, G.~W.\ 2013,
Proceedings of the National Academy of Science, 110, 19273

\bibitem[Rogers(2015)]{Rogers:2015}
Rogers, L.~A.\ 2015, \apj, 801, 41

\bibitem[Smith \etal(2012)]{Smith:2012}
Smith, J.~C., Stumpe, M.~C., Van Cleve, J.~E., \etal\ 2012, \pasp, 124, 1000

\bibitem[Stumpe \etal(2012)]{Stumpe:2012}
Stumpe, M.~C., Smith, J.~C., Van Cleve, J.~E., \etal\ 2012, \pasp, 124, 985

\bibitem[Tamuz \etal(2005)]{Tamuz:2005}
Tamuz, O., Mazeh, T., \& Zucker, S.\ 2005, \mnras, 356, 1466

\bibitem[Vanderburg \& Johnson(2014)]{Vanderburg:2014}
Vanderburg, A., \& Johnson, J.~A.\ 2014, \pasp, 126, 948

\bibitem[Vanderburg \etal(2015)]{Vanderburg:2015}
Vanderburg, A., Montet, B.~T., Johnson, J.~A., \etal\ 2015, \apj, 800, 59

\bibitem[Wang \etal(2015)]{Wang:2015}
Wang, D., Foreman-Mackey, D., Hogg, D.~W., \& Sch{\"o}lkopf, B.\ 2015,
American Astronomical Society Meeting Abstracts, 225, \#258.08

\bibitem[Youdin(2011)]{Youdin:2011}
Youdin, A.~N.\ 2011, \apj, 742, 38

\end{thebibliography}

\end{document}
